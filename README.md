
# Live 3D Reconstruction Demos

## Description
This project showcases real-time point cloud fusion of multiple RGB-D cameras using 2D marker based calibration.

---

## Demos
### Video 1: [Point Cloud Reconstruction]
The designed algorithm yielded a 90% reconstruction accuracy compared to manual scans.

<div align="center">
  <p>The following images were used for reconstruction:</p>
  <img src="img1.png" alt="Color Image 1" width="45%" style="margin: 0 2%;" />
  <img src="img2.png" alt="Color Image 2" width="45%" style="margin: 0 2%;" />
</div>

https://github.com/user-attachments/assets/da45727c-75bd-45df-a75b-5b7e36bd02e7

### Video 2: [Live Reconstruction Demo]
This demo showcases the reconstruction accuracy of the algorithm when deployed to live video. In this demo, two Intel Realsense L515 cameras were used. This application was developed in python using open3D rendering.

https://github.com/user-attachments/assets/4f1ab538-7247-42a8-9e91-89a1bf5b31a4

### Video 3: [Camera Extrinsic Location]
This demo shows the resulting camera extrinsics obtained from the calibration. This demo was created using Unreal Engine 5, and displayed on the Varjo XR3 headset.

https://github.com/user-attachments/assets/03099aa6-d8f5-4cc5-931c-8f19bc6fa4e2

---

## Contact
This project showcases my ongoing work with VeyondMetaverse. For further details or inquiries, feel free to reach out to me at nkarki@torontomu.ca.

