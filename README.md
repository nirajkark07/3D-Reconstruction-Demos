
# Live 3D Reconstruction Demo

## Description
This project showcases real-time point cloud fusion of multiple RGB-D cameras using 2D marker based calibration.

---

## Demos
### Video 1: [Point Cloud Reconstruction Accuracy]
The designed algorithm yielded a 90% reconstruction accuracy compared to manual scans.

<div align="center">
  <p>The following images were used for reconstruction:</p>
  <img src="img1.png" alt="Color Image 1" width="45%" style="margin: 0 2%;" />
  <img src="img2.png" alt="Color Image 2" width="45%" style="margin: 0 2%;" />
</div>

![Demo 1](PointCloudFusionDemo.mp4)

### Video 2: [Live Reconstruction Demo]
This demo showcases the reconstruction accuracy of the algorithm when deployed to live video. In this demo, two Intel Realsense L515 cameras were used.

![Demo 2](MultiCameraFusionDemo.mp4)

### Video 3: [Camera Extrinsic Location]
This demo illustrates the resulting camera extrinsics obtaind from the calibration. This demo was created using Unreal Engine 5, and displayed on the Varjo XR3 headset.
![Demo 3](XRCameraLocationDemo.mp4)

---

## Contact
This project showcases my ongoing work with VeyondMetaverse. For further details or inquiries, feel free to reach out to me at nkarki@torontomu.ca.

